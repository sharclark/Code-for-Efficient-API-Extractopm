{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71bb465b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Additional Imports\n",
    "import os, json, math, time\n",
    "from yelpapi import YelpAPI\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0551b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<yelpapi.yelpapi.YelpAPI at 0x111400f70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load API Credentials\n",
    "with open('/Users/sharheatherclark/.secret/yelp_api.json') as f:   #use your path here!\n",
    "    login = json.load(f)\n",
    "# Instantiate YelpAPI Variable\n",
    "yelp_api = YelpAPI(login['api-key'], timeout_s=5.0)\n",
    "yelp_api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4014a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set our API call parameters and define our search\n",
    "LOCATION = 'NY,NY'\n",
    "TERM = 'Pizza'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "682368c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data/results_in_progress_NY_pizza.json'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specifying JSON_FILE filename (can include a folder)\n",
    "# include the search terms in the filename\n",
    "JSON_FILE = \"Data/results_in_progress_NY_pizza.json\"\n",
    "JSON_FILE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7bfba07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Data/results_in_progress_NY_pizza.json not found. Saving empty list to file.\n"
     ]
    }
   ],
   "source": [
    "## Check if JSON_FILE exists\n",
    "file_exists = os.path.isfile(JSON_FILE)\n",
    "## If it does not exist: \n",
    "if file_exists == False:\n",
    "    \n",
    "    ## CREATE ANY NEEDED FOLDERS\n",
    "    # Get the Folder Name only\n",
    "    folder = os.path.dirname(JSON_FILE)\n",
    "    ## If JSON_FILE included a folder:\n",
    "    if len(folder)>0:\n",
    "        # create the folder\n",
    "        os.makedirs(folder,exist_ok=True)\n",
    "        \n",
    "        \n",
    "    ## INFORM USER AND SAVE EMPTY LIST\n",
    "    print(f'[i] {JSON_FILE} not found. Saving empty list to file.')\n",
    "    \n",
    "    \n",
    "    # save an empty list\n",
    "    with open(JSON_FILE,'w') as f:\n",
    "        json.dump([],f)  \n",
    "# If it exists, inform user\n",
    "else:\n",
    "    print(f\"[i] {JSON_FILE} already exists.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa6c58a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 0 previous results found.\n"
     ]
    }
   ],
   "source": [
    "## Load previous results and use len of results for offset\n",
    "with open(JSON_FILE,'r') as f:\n",
    "    previous_results = json.load(f)\n",
    "    # this code above renames file previous results instead of JSON_FILE\n",
    "    \n",
    "## set offset based on previous results\n",
    "n_results = len(previous_results)\n",
    "print(f'- {n_results} previous results found.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90067a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['businesses', 'total', 'region'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use our yelp_api variable's search_query method to perform our API call\n",
    "results = yelp_api.search_query(location=LOCATION,\n",
    "                                term=TERM,\n",
    "                               offset=n_results)\n",
    "results.keys()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb4bf984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16200"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## How many results total?\n",
    "total_results = results['total']\n",
    "total_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32baac51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## How many did we get the details for?\n",
    "results_per_page = len(results['businesses'])\n",
    "results_per_page\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c7c9b3",
   "metadata": {},
   "source": [
    "There are over 11000 businesses to retrieve from our API and we can get 20 results at a time (per \"page\").\n",
    "- We can calculate the # of results remaining by subtracting our offset (length of our previous results) from our total.\n",
    "- Then we can determining how many pages we will need by dividing the results by 20 (or whatever the value happens to be for results per page)\n",
    "- Note that we need to round up the number of pages in order to get all of the results. Even if there is only 1 result on the last page, we want to include that page! To do this we will use math.ceil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62eec602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "810"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import additional packages for controlling our loop\n",
    "import time, math\n",
    "\n",
    "# Use math.ceil to round up for the total number of pages of results.\n",
    "n_pages = math.ceil((results['total']-n_results)/ results_per_page)\n",
    "n_pages\n",
    "\n",
    "#This code/output says that we need 820 pages to get all the data we want"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e415581",
   "metadata": {},
   "source": [
    "You can see that having to manually go through 560 pages would be quite time consuming and inefficient! First we are going to save the first page into our file, and then we will add on to it with a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd3be1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join new results with old list with extend and save to file\n",
    "previous_results.extend(results['businesses'])  \n",
    "with open(JSON_FILE,'w') as f:\n",
    "     json.dump(previous_results,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8db6194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "626c35e8ed9b4d5fa812c03818f1ed9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/810 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#showing the tqdm working\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import time\n",
    "for i in tqdm_notebook(range(n_pages)):\n",
    "    # adds 200 ms pause\n",
    "    time.sleep(.2) \n",
    "#code above is looping through a pause every 820 bc range is n_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ee2ba5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5cc88c612714eebb1013d744a54ae74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/810 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "YelpAPIError",
     "evalue": "VALIDATION_ERROR: Too many results requested, limit+offset must be <= 1000.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mYelpAPIError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m n_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(previous_results)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m## use n_results as the OFFSET \u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43myelp_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLOCATION\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mterm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTERM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m## append new results and save to file\u001b[39;00m\n\u001b[1;32m     14\u001b[0m previous_results\u001b[38;5;241m.\u001b[39mextend(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbusinesses\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/dojo-env/lib/python3.9/site-packages/yelpapi/yelpapi.py:251\u001b[0m, in \u001b[0;36mYelpAPI.search_query\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA valid location (parameter \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m) or latitude/longitude combination \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    249\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(parameters \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m) must be provided.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSEARCH_API_URL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dojo-env/lib/python3.9/site-packages/yelpapi/yelpapi.py:299\u001b[0m, in \u001b[0;36mYelpAPI._query\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# Yelp can return one of many different API errors, so check for one of them.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# The Yelp Fusion API does not yet have a complete list of errors, but this is on the TODO list; see\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;66;03m# https://github.com/Yelp/yelp-fusion/issues/95 for more info.\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response_json:\n\u001b[0;32m--> 299\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m YelpAPI\u001b[38;5;241m.\u001b[39mYelpAPIError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(response_json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    300\u001b[0m                                                response_json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m    302\u001b[0m \u001b[38;5;66;03m# we got a good response, so return\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response_json\n",
      "\u001b[0;31mYelpAPIError\u001b[0m: VALIDATION_ERROR: Too many results requested, limit+offset must be <= 1000."
     ]
    }
   ],
   "source": [
    "for i in tqdm_notebook( range(1,n_pages+1)):\n",
    "    \n",
    "    ## Read in results in progress file and check the length\n",
    "    with open(JSON_FILE, 'r') as f:\n",
    "        previous_results = json.load(f)\n",
    "    ## save number of results for to use as offset\n",
    "    n_results = len(previous_results)\n",
    "    ## use n_results as the OFFSET \n",
    "    results = yelp_api.search_query(location=LOCATION,\n",
    "                                    term=TERM, \n",
    "                                    offset=n_results)\n",
    "    \n",
    "    ## append new results and save to file\n",
    "    previous_results.extend(results['businesses'])\n",
    "    \n",
    "    with open(JSON_FILE,'w') as f:\n",
    "        json.dump(previous_results,f)\n",
    "    \n",
    "    # add a 200ms pause\n",
    "    time.sleep(.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cbec8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## delete file and confirm it no longer exits.\n",
    "os.remove(JSON_FILE)\n",
    "os.path.isfile(JSON_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f566589b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<tokenize>:17\u001b[0;36m\u001b[0m\n\u001b[0;31m    else:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "def create_json_file(JSON_FILE,  delete_if_exists=False):\n",
    "    \n",
    "    ## Check if JSON_FILE exists\n",
    "    file_exists = os.path.isfile(JSON_FILE)\n",
    "    \n",
    "    ## If it DOES exist:\n",
    "    if file_exists == True:\n",
    "        \n",
    "        ## Check if user wants to delete if exists\n",
    "        if delete_if_exists==True:\n",
    "            \n",
    "            print(f\"[!] {JSON_FILE} already exists. Deleting previous file...\")\n",
    "            ## delete file and confirm it no longer exits.\n",
    "            os.remove(JSON_FILE)\n",
    "            ## Recursive call to function after old file deleted\n",
    "            create_json_file(JSON_FILE,delete_if_exists=False)\n",
    "        else:\n",
    "            print(f\"[i] {JSON_FILE} already exists.\")            \n",
    "            \n",
    "            \n",
    "    ## If it does NOT exist:\n",
    "    else:\n",
    "        \n",
    "        ## INFORM USER AND SAVE EMPTY LIST\n",
    "        print(f\"[i] {JSON_FILE} not found. Saving empty list to new file.\")\n",
    "        \n",
    "        ## CREATE ANY NEEDED FOLDERS\n",
    "        # Get the Folder Name only\n",
    "        folder = os.path.dirname(JSON_FILE)\n",
    "        \n",
    "        ## If JSON_FILE included a folder:\n",
    "        if len(folder)>0:\n",
    "            # create the folder\n",
    "            os.makedirs(folder,exist_ok=True)\n",
    "        ## Save empty list to start the json file\n",
    "        with open(JSON_FILE,'w') as f:\n",
    "            json.dump([],f)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6fe4edeb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_json_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## Create a new empty json file (exist the previous if it exists)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcreate_json_file\u001b[49m(JSON_FILE, delete_if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m## Load previous results and use len of results for offset\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(JSON_FILE,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_json_file' is not defined"
     ]
    }
   ],
   "source": [
    "## Create a new empty json file (exist the previous if it exists)\n",
    "create_json_file(JSON_FILE, delete_if_exists=True)\n",
    "## Load previous results and use len of results for offset\n",
    "with open(JSON_FILE,'r') as f:\n",
    "    previous_results = json.load(f)\n",
    "    \n",
    "## set offset based on previous results\n",
    "n_results = len(previous_results)\n",
    "print(f'- {n_results} previous results found.')\n",
    "# use our yelp_api variable's search_query method to perform our API call\n",
    "results = yelp_api.search_query(location=LOCATION,\n",
    "                                term=TERM,\n",
    "                               offset=n_results)\n",
    "## How many results total?\n",
    "total_results = results['total']\n",
    "## How many did we get the details for?\n",
    "results_per_page = len(results['businesses'])\n",
    "# Use math.ceil to round up for the total number of pages of results.\n",
    "n_pages = math.ceil((results['total']-n_results)/ results_per_page)\n",
    "n_pages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b509386",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm_notebook( range(1,n_pages+1)):\n",
    "    \n",
    "    ## Read in results in progress file and check the length\n",
    "    with open(JSON_FILE, 'r') as f:\n",
    "        previous_results = json.load(f)\n",
    "    ## save number of results for to use as offset\n",
    "    n_results = len(previous_results)\n",
    "    \n",
    "    if (n_results + results_per_page) > 1000:\n",
    "        print('Exceeded 1000 api calls. Stopping loop.')\n",
    "        break\n",
    "    \n",
    "    ## use n_results as the OFFSET \n",
    "    results = yelp_api.search_query(location=LOCATION,\n",
    "                                    term=TERM, \n",
    "                                    offset=n_results)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## append new results and save to file\n",
    "    previous_results.extend(results['businesses'])\n",
    "    \n",
    "    # display(previous_results)\n",
    "    with open(JSON_FILE,'w') as f:\n",
    "        json.dump(previous_results,f)\n",
    "    \n",
    "    time.sleep(.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b576fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load final results\n",
    "final_df = pd.read_json(JSON_FILE)\n",
    "display(final_df.head(), final_df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3e2538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicate results\n",
    "final_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a18377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicate ID's \n",
    "final_df.duplicated(subset='id').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2a2fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop duplicate ids and confirm there are no more duplicates\n",
    "final_df = final_df.drop_duplicates(subset='id')\n",
    "final_df.duplicated(subset='id').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fb3c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the final results to a compressed csv\n",
    "final_df.to_csv('Data/final_results_NY_pizza.csv.gz', compression='gzip',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39276a59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327abe14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8f89e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfc9e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
